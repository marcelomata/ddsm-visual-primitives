{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torchnet\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from munch import Munch\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch 0.2 and torchvision 0.1.9\n",
    "# import sys\n",
    "# import torchvision\n",
    "# assert sys.version.startswith('2')\n",
    "# assert torch.__version__.startswith('0.2')\n",
    "# assert '0.1.9' in torchvision.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pretrained network of your choice:\n",
    "\n",
    "# pretrained alexnet\n",
    "# config_path = 'pretrained/alexnet/config.yml'\n",
    "# epoch = 45\n",
    "\n",
    "# pretrained vgg16\n",
    "#config_path = 'pretrained/vgg16/config.yml'\n",
    "#epoch = 12\n",
    "\n",
    "# pretrained inception_v3\n",
    "#config_path = 'pretrained/inception_v3/config.yml'\n",
    "#epoch = 7\n",
    "\n",
    "\n",
    "## The difference between resnet152 and resnet152_3class\n",
    "## is that the 3 class model predicts malignant/benign/normal\n",
    "## and the 2 class model predicts cancer/no cancer.\n",
    "\n",
    "# pretrained resnet152\n",
    "#config_path = 'pretrained/resnet152/config.yml'\n",
    "#epoch = 5\n",
    "\n",
    "# pretrained resnet152_3class\n",
    "config_path = 'pretrained/resnet152_3class/config.yml'\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a model you trained yourself! More exciting than the ones above ;)\n",
    "\n",
    "#config_path = 'logs/your_log_dir/config.yml'\n",
    "#epoch = your_best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model information such as Pytorch Checkpoint filename from config.yml\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    cfg = Munch.fromYAML(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet152'\n"
     ]
    }
   ],
   "source": [
    "# Create model instance from achitecture specified in config.yml\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "print(\"=> creating model '{}'\".format(cfg.arch.model))\n",
    "model = models.__dict__[cfg.arch.model](pretrained=cfg.arch.pretrained)\n",
    "\n",
    "if cfg.arch.model.startswith('alexnet') or cfg.arch.model.startswith('vgg'):\n",
    "    model.classifier._modules['6'] = nn.Linear(4096, cfg.arch.num_classes)\n",
    "elif cfg.arch.model == 'inception_v3':\n",
    "    model.aux_logits = False\n",
    "    model.fc = nn.Linear(2048, cfg.arch.num_classes)\n",
    "elif cfg.arch.model == 'resnet152':\n",
    "    model.fc = nn.Linear(2048, cfg.arch.num_classes)\n",
    "else:\n",
    "    raise Exception\n",
    "\n",
    "if cfg.arch.model.startswith('alexnet') or cfg.arch.model.startswith('vgg'):\n",
    "    model.features = torch.nn.DataParallel(model.features)\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "# In case you have a GPU    \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()    \n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'pretrained/resnet152_3class/checkpoint_00000005.pth.tar'\n",
      "=> loaded checkpoint 'pretrained/resnet152_3class/checkpoint_00000005.pth.tar' (epoch 5)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "\n",
    "resume_path = cfg.training.resume.replace(cfg.training.resume[-16:-8], '{:08}'.format(epoch))\n",
    "if os.path.isfile(resume_path):\n",
    "    print(\"=> loading checkpoint '{}'\".format(resume_path))\n",
    "    if torch.cuda.is_available():\n",
    "        # Pretrained models were created with CUDA enabled\n",
    "        checkpoint = torch.load(resume_path)\n",
    "    else:\n",
    "        # For if you want to run this notebook with pretrained models on a CPU only machine\n",
    "        checkpoint = torch.load(resume_path, map_location='cpu')\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume_path, checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(resume_path))\n",
    "    print('')\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing transform, classic ImageNet mean and std\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "val_transforms = []\n",
    "if cfg.arch.model == 'inception_v3':\n",
    "    val_transforms.append(transforms.Resize(299))\n",
    "else:\n",
    "    val_transforms.append(transforms.Resize(224))\n",
    "val_dataset = dataset.DDSM(cfg.data.root, 'val', transforms.Compose(val_transforms + [\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "]))\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=cfg.data.batch_size, shuffle=False,\n",
    "    num_workers=cfg.data.workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/ddsm_3class\n"
     ]
    }
   ],
   "source": [
    "# Check! Location of ddsm image files\n",
    "print(cfg.data.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set size = 44612\n",
      "Number of unique patients in val set: 1040\n",
      "Example fname from val set: ('images/778/benign_01-B_3099_1.LEFT_CC.LJPEG.1-x630_y0_w630_h630_imgfrac0.25_stridefrac0.5.jpg', 0)\n"
     ]
    }
   ],
   "source": [
    "# Print some details about the validation set we will be using to calculate ROC\n",
    "# Just a check to make sure everything is where we expect\n",
    "\n",
    "print(f'Val set size = {len(val_dataset)}')\n",
    "print(f\"Number of unique patients in val set: {len(set([s[0].split('/')[-1].split('-x')[0] for s in val_dataset.image_list]))}\")\n",
    "print(f'Example fname from val set: {val_dataset.image_list[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7246c11161b44aa9a425b3860d680736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1395), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Print per-class AUC values, using torchnet AUC function\n",
    "\n",
    "targets = [[] for _ in range(cfg.arch.num_classes)]\n",
    "probs = [[] for _ in range(cfg.arch.num_classes)]\n",
    "aucs = [torchnet.meter.AUCMeter() for _ in range(cfg.arch.num_classes)]\n",
    "\n",
    "for inp, target in tqdm(val_loader):\n",
    "    input_var = Variable(inp, volatile=True)\n",
    "    output = model(input_var)\n",
    "    prob = nn.Softmax()(output)\n",
    "    for i in range(cfg.arch.num_classes):\n",
    "        aucs[i].add(prob[:, i].data, target == i)\n",
    "        targets[i].extend(target.numpy() == i)\n",
    "        probs[i].extend(prob[:, i].data.cpu().numpy())\n",
    "\n",
    "for i in xrange(cfg.arch.num_classes):\n",
    "    print('class {}'.format(i))\n",
    "    print('torchnet.meter.AUCMeter: {}'.format(aucs[i].value()[0]))\n",
    "    print('sklearn.metrics.roc_auc_score: {}'.format(roc_auc_score(targets[i], probs[i])))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC for one class\n",
    "def plot_roc_curve(y_true, y_score):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC Curve')\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    plt.plot(fpr, tpr, color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC plots for each class\n",
    "for i in xrange(cfg.arch.num_classes):\n",
    "    print('class {}'.format(i))\n",
    "    plot_roc_curve(targets[i], probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_auc(fpr, tpr, thresh):\n",
    "    loc = len([t for t in tpr if t >= thresh])\n",
    "    pAUC = np.trapz(tpr[-1*loc:], fpr[-1*loc:]) * (1-thresh)\n",
    "    return pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print partial AUC over threshold of 0.8 \n",
    "# Common metric for medical tasks where sensitivity at set specificity is important. \n",
    "\n",
    "i = 1\n",
    "fpr, tpr, _ = roc_curve(targets[i], probs[i])\n",
    "pAUC = partial_auc(fpr, tpr, 0.8)\n",
    "plt.plot(fpr[-1*loc:], tpr[-1*loc:], color='black')\n",
    "plt.show()\n",
    "print(pAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for all 3 classes' ROC and pAUC \n",
    "\n",
    "def plot_multi_roc_curve(ys_true, ys_score, legend):\n",
    "    n_classes = len(ys_true)\n",
    "    \n",
    "    # First aggregate all false positive rates\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    pauc = dict()\n",
    "    for i in range(n_classes):        \n",
    "        fpr[i], tpr[i], _ = roc_curve(ys_true[i], ys_score[i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        pauc[i] = partial_auc(fpr[i], tpr[i], thresh = 0.8)\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    \n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.gca().set_aspect('equal')\n",
    "    lw = 2\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='Class {0} ( AUC = {1:0.3f}, pAUC = {2:0.3f} )'\n",
    "                 ''.format(legend[i], roc_auc[i], pauc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.plot([0, 1], [0.8, 0.8], color='navy', linestyle=':', \n",
    "             lw=lw, label='Partial AUC threshold = 0.8 TPR')\n",
    "\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    #plt.title('ResNet152 3class ROC')\n",
    "    plt.legend(loc=\"lower right\", fontsize=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves for each class overlayed, with pAUC indicated\n",
    "plot_multi_roc_curve(targets, probs, ['Not Malignant', 'Malignant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Precision of this model\n",
    "# Please note this AP score is caluclated using the sklearn method, \n",
    "# which is not the standarad Pascal VOC AP metric.\n",
    "# Included for reference only.\n",
    "\n",
    "print(f'AP for this model: {average_precision_score(targets[1],probs[1])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
